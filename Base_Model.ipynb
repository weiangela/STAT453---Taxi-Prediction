{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8135a9-a8e9-4e5b-8a7b-2d3f6a4ffb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angelawei/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/angelawei/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /Users/angelawei/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <AD0702F8-F0F4-3872-8C19-A834018634B4> /Users/angelawei/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f7cdff-0e7f-4bc0-9c9a-bcbbf0f90f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pq.read_table('./Data/cleaned_taxi_data.parquet')\n",
    "temp = temp.to_pandas()\n",
    "\n",
    "trip_inf_loc = list(range(0, 4)) + list(range(6, 172))\n",
    "tip_inf_loc = [4] + list(range(173, 176))\n",
    "trip_info = torch.tensor(temp.iloc[:, trip_inf_loc].values)\n",
    "tip_info = torch.tensor(temp.iloc[:, tip_inf_loc].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b1baed-8339-4f0b-935a-878be1f56c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base values\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97507d10-82d2-4ed5-bd0c-98fd88af464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and Split Input Data (Train = 75% (1,707,346), Validation = 20% (455,292), Test = 5% (113,823))\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(trip_info,  [0.75, 0.2, 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1eadaf7-e696-417e-a2f5-e04a8a6b2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADERS\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=4)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3b037-a3a4-4f12-a8ec-94c39550443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden_1, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.linear_1.weight.size(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### MAKE SURE YOU CONNECT THE LAYERS PROPERLY IF YOU CHANGED\n",
    "        ### ANYTHNG IN THE __init__ METHOD ABOVE       \n",
    "        out = self.linear_1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        logits = self.linear_out(out)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "    \n",
    "#################################\n",
    "### Model Initialization\n",
    "#################################\n",
    "\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = MLP(num_features=171,\n",
    "            num_hidden_1=100,\n",
    "            num_classes=10)\n",
    "\n",
    "\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c0623-069d-4b7f-aa50-d728a213f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep?\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def compute_accuracy_and_loss(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    cross_entropy = 0.\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.view(-1, 28*28).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        cross_entropy += F.cross_entropy(logits, targets).item()\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100, cross_entropy/num_examples\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "train_acc_lst, valid_acc_lst = [], []\n",
    "train_loss_lst, valid_loss_lst = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.view(-1, 28*28).to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        #if not batch_idx % 20:\n",
    "        #    print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "        #           f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "        #           f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE)\n",
    "        valid_acc, valid_loss = compute_accuracy_and_loss(model, valid_loader, device=DEVICE)\n",
    "        train_acc_lst.append(train_acc)\n",
    "        valid_acc_lst.append(valid_acc)\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
